{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "## for data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "import re\n",
    "\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## for machine learning\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## Chinese display\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "## No warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 220)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file = \"data/Diarrhea_embed_219.tsv\"\n",
    "df = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8120, 219) | X_test shape: (3480, 219)\n",
      "y_train mean: 0.2 | y_test mean: 0.2\n",
      "--------------------------------------------------\n",
      "Train set：\n",
      "0    0.795813\n",
      "1    0.204187\n",
      "Name: 细菌结果, dtype: float64\n",
      "Test set：\n",
      "0    0.79569\n",
      "1    0.20431\n",
      "Name: 细菌结果, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Stratified sampling\n",
    "y = \"细菌结果\"\n",
    "df_train, df_test = train_test_split(df, test_size=0.3,\n",
    "                                     stratify=df[y], random_state=42)\n",
    "\n",
    "# print info\n",
    "print(\"X_train shape:\", df_train.drop(y, axis=1).shape,\n",
    "      \"| X_test shape:\", df_test.drop(y, axis=1).shape)\n",
    "print(\"y_train mean:\", round(\n",
    "    np.mean(df_train[y]), 2), \"| y_test mean:\", round(np.mean(df_test[y]), 2))\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "print(\"Train set：\")\n",
    "print(df_train[y].value_counts() / len(df_train[y]))\n",
    "print(\"Test set：\")\n",
    "print(df_test[y].value_counts() / len(df_test[y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_raw = df.drop(y, axis=1).columns.to_list()\n",
    "df_train.reset_index(inplace=True)\n",
    "df_test.reset_index(inplace=True)\n",
    "\n",
    "X_train = df_train[features_raw]\n",
    "y_train = df_train[y]\n",
    "\n",
    "X_test = df_test[features_raw]\n",
    "y_test = df_test[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['区县', '性别', '户籍', '职业', '首发症状', '发热', '脱水', '腹胀', '恶心', '里急后重', '肠鸣音亢进', '腹痛', '腹痛性质', '腹痛部位', '呕吐', '呕吐在腹泻___发生', '腹泻', '腹泻性质', '神经症状', '中毒症状', '其他症状', '近6个月有无肠道疾病既往史', '发病前五天内是否有不洁饮食史', '进餐地点', '发病前5天内是否有不洁饮水史', '发病前5天内周边有无类似腹泻病例', '发病前5天内是否有聚餐史', '发病前一周是否外出', '是否家中饲养或接触过宠物', '就诊前是否服用过抗生素', '诊断', '诊断类型', '临床处理', '本次就诊是否给予抗生素', '抗生素名称.1', '是否采集', '采样类型', 'age', '体温', '呕吐频次', '持续天数', '腹泻量', '腹泻频次', '腹泻天数', '疑似病例人数']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = re.compile(r'(.+)_dim')\n",
    "feature_list = []\n",
    "for value in df.columns.tolist():\n",
    "    temp = \"\".join(f.findall(value))\n",
    "    if temp not in feature_list and temp:\n",
    "        feature_list.append(temp)\n",
    "numeric = ['age', '体温', '呕吐频次', '持续天数', '腹泻量', '腹泻频次', '腹泻天数', '疑似病例人数']\n",
    "feature_list = feature_list + numeric\n",
    "print(feature_list)\n",
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2array(df):\n",
    "    \"\"\"\n",
    "    df --> array\n",
    "    \"\"\"\n",
    "    df_array = np.zeros((df.shape[0], len(feature_list), 47))\n",
    "    for i in range(df.shape[0]):\n",
    "        for j, value in enumerate(feature_list):\n",
    "            for k in range(47):\n",
    "                try:\n",
    "                    df_array[i,j,k] = df.loc[i,value+'_dim'+str(k)]\n",
    "                except:\n",
    "                    break\n",
    "    return df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = df2array(X_train)\n",
    "X_test_array = df2array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8120, 45, 47)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3480, 45, 47)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array.shape  # (8120, 45, 47)\n",
    "X_test_array.shape   # (3480, 45, 47)\n",
    "\n",
    "y_train_array = y_train.values\n",
    "y_test_array = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8120, 1, 45, 47]), torch.Size([8120]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train set\n",
    "# converting array into torch format\n",
    "train_x = X_train_array.reshape(8120, 1, 45, 47)\n",
    "train_x = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = y_train_array.astype(int)\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "# shape of training data\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3480, 1, 45, 47]), torch.Size([3480]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test set\n",
    "# converting array into torch format\n",
    "test_x = X_test_array.reshape(3480, 1, 45, 47)\n",
    "test_x = torch.from_numpy(test_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "test_y = y_test_array.astype(int)\n",
    "test_y = torch.from_numpy(test_y)\n",
    "\n",
    "# shape of training data\n",
    "test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMaxPool1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalMaxPool1d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, num_filters, n_out)\n",
    "        return shape: (batch_size, num_filters, 1)\n",
    "        \"\"\"\n",
    "        return F.max_pool1d(x, kernel_size=x.shape[2])\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, embed_size, num_classes, num_filters=100, \n",
    "                 filter_sizes=[2,3,4], hidden_size=128, dropout_rate=0.3):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(in_channels=1, \n",
    "                                              out_channels=num_filters, \n",
    "                                              kernel_size=(k, embed_size), \n",
    "                                              padding=(k - 1, 0)) for k in filter_sizes])\n",
    "        self.max_pool = GlobalMaxPool1d()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(len(filter_sizes) * num_filters, hidden_size, bias=True)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, 1, feature_number, embed_size)\n",
    "        return shape: (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        convolution = [conv(x) for conv in self.convs]  # (batch_size, num_filters, n_out, 1) \n",
    "        max1 = self.max_pool(convolution[0].squeeze())  # (batch_size, num_filters, 1)\n",
    "        max2 = self.max_pool(convolution[1].squeeze())\n",
    "        max3 = self.max_pool(convolution[2].squeeze())\n",
    "        cat = torch.cat((max1, max2, max3), dim=2)  # （batch_size, num_filters, 1*len(filter_sizes)）  \n",
    "        x = cat.view(cat.shape[0], -1)  # (batch_size, num_filter * len(filter_sizes))\n",
    "        x = self.fc1(self.relu(x))  # (batch_size, hidden_size)\n",
    "        x = self.dropout(x)  # (batch_size, hidden_size)\n",
    "        outputs = self.fc2(x)  # (batch_size, num_classes) \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embed_size = 47\n",
    "num_classes = 2\n",
    "num_filters = 100\n",
    "filter_sizes = [2, 3, 4]\n",
    "hidden_size = 128\n",
    "dropout_rate = 0.3\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(1, 100, kernel_size=(2, 47), stride=(1,), padding=(1, 0))\n",
       "    (1): Conv1d(1, 100, kernel_size=(3, 47), stride=(1,), padding=(2, 0))\n",
       "    (2): Conv1d(1, 100, kernel_size=(4, 47), stride=(1,), padding=(3, 0))\n",
       "  )\n",
       "  (max_pool): GlobalMaxPool1d()\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=300, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(embed_size, num_classes, num_filters,\n",
    "            filter_sizes, hidden_size, dropout_rate)\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # getting the training set\n",
    "    x_train, y_train = Variable(train_x), Variable(train_y)\n",
    "    # converting the data into GPU format\n",
    "    x_train = x_train.to(device, dtype=torch.float)\n",
    "    y_train = y_train.to(device, dtype=torch.long)\n",
    "\n",
    "    # clearing the Gradients of the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # prediction for training set\n",
    "    output_train = model(x_train)\n",
    "\n",
    "    # computing the training loss\n",
    "    loss_train = criterion(output_train, y_train)\n",
    "    train_losses.append(loss_train)\n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    if epoch%50 == 0:\n",
    "        # printing the validation loss\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5000\n",
    "# empty list to store training losses\n",
    "train_losses = []\n",
    "# empty list to store validation losses\n",
    "val_losses = []\n",
    "# training the model: final_loss is 0.14\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(1, 100, kernel_size=(2, 47), stride=(1,), padding=(1, 0))\n",
       "    (1): Conv1d(1, 100, kernel_size=(3, 47), stride=(1,), padding=(2, 0))\n",
       "    (2): Conv1d(1, 100, kernel_size=(4, 47), stride=(1,), padding=(3, 0))\n",
       "  )\n",
       "  (max_pool): GlobalMaxPool1d()\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=300, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC | F1-Score | Precision | Recall\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_test= Variable(test_x)\n",
    "    x_test = x_test.to(device, dtype=torch.float)\n",
    "    output_test = model(x_test)\n",
    "\n",
    "softmax = torch.exp(output_test).cpu()\n",
    "predicted_prob = list(softmax.numpy())\n",
    "predicted = np.argmax(predicted_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(y_test, predicted):\n",
    "\n",
    "    # Accuray e AUC\n",
    "    accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "    auc = metrics.roc_auc_score(y_test, predicted)\n",
    "    print(\"Accuracy (overall correct predictions):\",  round(accuracy, 2))\n",
    "    print(\"Auc:\", round(auc, 2))\n",
    "\n",
    "    # Precision e Recall\n",
    "    recall = metrics.recall_score(y_test, predicted)\n",
    "    precision = metrics.precision_score(y_test, predicted)\n",
    "    print(\"Recall (all 1s predicted right):\", round(recall, 2))\n",
    "    print(\"Precision (confidence when predicting a 1):\", round(precision, 2))\n",
    "    print(\"Detail:\")\n",
    "    print(metrics.classification_report(y_test, predicted,\n",
    "          target_names=[str(i) for i in np.unique(y_test)]))\n",
    "\n",
    "    # confusion matrix\n",
    "    classes = np.unique(y_test)\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    cm = metrics.confusion_matrix(y_test, predicted, labels=classes)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Blues, cbar=False)\n",
    "    ax.set(xlabel=\"Pred\", ylabel=\"True\", title=\"Confusion matrix\")\n",
    "    ax.set_yticklabels(labels=classes, rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return recall, precision, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (overall correct predictions): 0.75\n",
      "Auc: 0.63\n",
      "Recall (all 1s predicted right): 0.42\n",
      "Precision (confidence when predicting a 1): 0.39\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      2769\n",
      "           1       0.39      0.42      0.41       711\n",
      "\n",
      "    accuracy                           0.75      3480\n",
      "   macro avg       0.62      0.63      0.62      3480\n",
      "weighted avg       0.75      0.75      0.75      3480\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall, precision, cm = eval(test_y, predicted)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3ae07b93995e50bb71287119e2028dbb16c44e45ae3a719083b6c414ea5ab0a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
