{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291c7f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T04:18:40.634790Z",
     "start_time": "2021-11-08T04:18:37.663972Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "## For data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## For machine learning\n",
    "from sklearn import preprocessing, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## Chinese display\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "## No warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3123bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(X_test, y_test, predicted, predicted_prob, show=False):\n",
    "\n",
    "    # Accuray e AUC\n",
    "    accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "    auc = metrics.roc_auc_score(y_test, predicted_prob)\n",
    "    if show:\n",
    "        print(\"Accuracy (overall correct predictions):\",  round(accuracy, 4))\n",
    "        print(\"Auc:\", round(auc, 4))\n",
    "\n",
    "    # Precision & Recall\n",
    "    recall = metrics.recall_score(y_test, predicted)\n",
    "    precision = metrics.precision_score(y_test, predicted)\n",
    "    if show:\n",
    "        print(\"Recall (all 1s predicted right):\", round(recall, 4))\n",
    "        print(\"Precision (confidence when predicting a 1):\", round(precision, 4))\n",
    "        print(\"Detail:\")\n",
    "        print(metrics.classification_report(y_test, predicted,\n",
    "            target_names=[str(i) for i in np.unique(y_test)]))\n",
    "    \n",
    "    # f-1\n",
    "    precision_, recall_, f_1, support = precision_recall_fscore_support(\n",
    "        y_true=y_test, y_pred=predicted,beta=1)\n",
    "    if show:\n",
    "        print(f'F1 value: {f_1[1]}')\n",
    "\n",
    "    # f-beta\n",
    "    precision_, recall_, f_beta, support = precision_recall_fscore_support(\n",
    "        y_true=y_test, y_pred=predicted,beta=1.5)\n",
    "    if show:\n",
    "        print(f'F-beta value: {f_beta[1]}')\n",
    "\n",
    "    # # confusion matrix\n",
    "    # classes = np.unique(y_test)\n",
    "    # fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    # cm = metrics.confusion_matrix(y_test, predicted, labels=classes)\n",
    "    # sns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Blues, cbar=False)\n",
    "    # ax.set(xlabel=\"Pred\", ylabel=\"True\", title=\"Confusion matrix\")\n",
    "    # ax.set_yticklabels(labels=classes, rotation=0)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return [recall, precision, f_1[1], f_beta[1]]\n",
    "\n",
    "\n",
    "# f_beta\n",
    "def calculate_fscore(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        Y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        stratify=Y,\n",
    "                                                        random_state=42)                                          \n",
    "    model = linear_model.LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predicted_prob = model.predict_proba(X_test)[:, 1]\n",
    "    predicted = model.predict(X_test)\n",
    "    test_metrics = eval(X_test, y_test, predicted, predicted_prob, True)\n",
    "\n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bae24a1",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "### 1. No feature selection\n",
    "#### 1.1 One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c630c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 383)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (overall correct predictions): 0.7098\n",
      "Auc: 0.7471\n",
      "Recall (all 1s predicted right): 0.616\n",
      "Precision (confidence when predicting a 1): 0.3728\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      2769\n",
      "           1       0.37      0.62      0.46       711\n",
      "\n",
      "    accuracy                           0.71      3480\n",
      "   macro avg       0.63      0.67      0.63      3480\n",
      "weighted avg       0.78      0.71      0.73      3480\n",
      "\n",
      "F1 value: 0.46447507953340406\n",
      "F-beta value: 0.5130191909181008\n"
     ]
    }
   ],
   "source": [
    "df_file = \"data/Diarrhea_fillna.tsv\"\n",
    "df1 = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "\n",
    "y = \"细菌结果\"\n",
    "df1[y] = df1[y].map(lambda x: 0 if x == \"阴性\" else 1)\n",
    "\n",
    "df1 = pd.get_dummies(df1, drop_first=True)\n",
    "df1.shape\n",
    "\n",
    "X_original = df1.drop(y, axis=1)\n",
    "y_original = df1[y]\n",
    "\n",
    "# [recall, precision, f_1[1], f_beta[1]]\n",
    "test_metrics = calculate_fscore(X_original, y_original)\n",
    "# print(\"No feature selection: f_beta of one-hot encoding: \", f_beta_original)\n",
    "# print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4101a",
   "metadata": {},
   "source": [
    "#### 1.2 Feature embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92d5debc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 101)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (overall correct predictions): 0.704\n",
      "Auc: 0.7397\n",
      "Recall (all 1s predicted right): 0.6118\n",
      "Precision (confidence when predicting a 1): 0.3659\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.73      0.80      2769\n",
      "         1.0       0.37      0.61      0.46       711\n",
      "\n",
      "    accuracy                           0.70      3480\n",
      "   macro avg       0.62      0.67      0.63      3480\n",
      "weighted avg       0.77      0.70      0.73      3480\n",
      "\n",
      "F1 value: 0.45789473684210524\n",
      "F-beta value: 0.5069475571492604\n"
     ]
    }
   ],
   "source": [
    "df_file = \"data/Diarrhea_embed_100.tsv\"\n",
    "df = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "df.shape\n",
    "\n",
    "y = \"细菌结果\"\n",
    "X_embed = df.drop(y, axis=1)\n",
    "y_embed = df[y]\n",
    "test_metrics = calculate_fscore(X_embed, y_embed)\n",
    "\n",
    "# print(\"No feature selection: f_beta of feature embedding: \", f_beta_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e54730",
   "metadata": {},
   "source": [
    "#### 1.3 One-hot encoding + feature embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8ad58cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 383)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(11600, 100)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(11600, 483)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file = \"data/Diarrhea_fillna.tsv\"\n",
    "df = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "y = \"细菌结果\"\n",
    "df[y] = df[y].map(lambda x: 0 if x == \"阴性\" else 1)\n",
    "df_onehot = pd.get_dummies(df, drop_first=True)\n",
    "df_onehot = df_onehot.reset_index(drop=True)\n",
    "df_onehot.shape\n",
    "\n",
    "df_file = \"data/Diarrhea_embed_100.tsv\"\n",
    "df_embed = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "y = \"细菌结果\"\n",
    "df_embed = df_embed.drop(y, axis=1)\n",
    "df_embed.shape\n",
    "\n",
    "df = pd.concat([df_onehot, df_embed], axis=1)\n",
    "df.shape\n",
    "\n",
    "df_combined = \"data/Diarrhea_onehot_embed_482.tsv\"\n",
    "df.to_csv(df_combined, sep=\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dae20a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 483)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (overall correct predictions): 0.7046\n",
      "Auc: 0.74\n",
      "Recall (all 1s predicted right): 0.616\n",
      "Precision (confidence when predicting a 1): 0.3671\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      2769\n",
      "           1       0.37      0.62      0.46       711\n",
      "\n",
      "    accuracy                           0.70      3480\n",
      "   macro avg       0.62      0.67      0.63      3480\n",
      "weighted avg       0.78      0.70      0.73      3480\n",
      "\n",
      "F1 value: 0.46008403361344535\n",
      "F-beta value: 0.5097126488228448\n"
     ]
    }
   ],
   "source": [
    "df_file = \"data/Diarrhea_onehot_embed_482.tsv\"\n",
    "df = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "df.shape\n",
    "\n",
    "y = \"细菌结果\"\n",
    "X_embed = df.drop(y, axis=1)\n",
    "y_embed = df[y]\n",
    "test_metrics = calculate_fscore(X_embed, y_embed)\n",
    "\n",
    "# print(\"No feature selection: f_beta of one-hot encoding and feature embedding: \", df_onehot_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a61d2",
   "metadata": {},
   "source": [
    "### 2. Statistical-based methods\n",
    "#### 2.1 One-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75e0ed19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 358)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (overall correct predictions): 0.7069\n",
      "Auc: 0.7469\n",
      "Recall (all 1s predicted right): 0.6203\n",
      "Precision (confidence when predicting a 1): 0.3703\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      2769\n",
      "           1       0.37      0.62      0.46       711\n",
      "\n",
      "    accuracy                           0.71      3480\n",
      "   macro avg       0.63      0.67      0.63      3480\n",
      "weighted avg       0.78      0.71      0.73      3480\n",
      "\n",
      "F1 value: 0.46372239747634064\n",
      "F-beta value: 0.513571620532115\n"
     ]
    }
   ],
   "source": [
    "df_file = \"data/Diarrhea_fillna.tsv\"\n",
    "df2 = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "\n",
    "y = \"细菌结果\"\n",
    "df2[y] = df2[y].map(lambda x: 0 if x == \"阴性\" else 1)\n",
    "\n",
    "# relevant features from 'main.ipynb'\n",
    "features_chi2_anova = [\n",
    "    'age', '体温', '腹泻量', '腹泻频次', '腹泻天数', '细菌结果', '区县', '性别', '户籍', '职业', '首发症状',\n",
    "    '发热', '腹胀', '恶心', '腹痛', '腹痛性质', '腹痛部位', '呕吐在腹泻___发生', '腹泻', '腹泻性质',\n",
    "    '近6个月有无肠道疾病既往史', '进餐地点', '是否家中饲养或接触过宠物', '就诊前是否服用过抗生素',\n",
    "    '诊断', '诊断类型', '临床处理', '本次就诊是否给予抗生素', '抗生素名称.1', '是否采集', '采样类型'\n",
    "]\n",
    "\n",
    "df2 = df2[features_chi2_anova]\n",
    "df2 = pd.get_dummies(df2, drop_first=True)\n",
    "df2.shape\n",
    "\n",
    "X_chi2_anova = df2.drop(y, axis=1)\n",
    "y_chi2_anova = df2[y]\n",
    "test_metrics = calculate_fscore(X_chi2_anova, y_chi2_anova)\n",
    "\n",
    "# print(\"Statistical-based method: f_beta of one-hot encoding: \", f_beta_chi2_anova)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb5295",
   "metadata": {},
   "source": [
    "### 3. Reinforcement Learning-based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f078b411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 46)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file = \"data/Diarrhea_fillna.tsv\"\n",
    "df = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5862fd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9231\n",
       "1    2369\n",
       "Name: 细菌结果, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = \"细菌结果\"\n",
    "df[y] = df[y].map(lambda x: 0 if x == \"阴性\" else 1)\n",
    "df[y].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148572cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T00:49:41.542089Z",
     "start_time": "2021-11-09T00:49:41.480075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 383)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.shape\n",
    "# 382 features (excluding the label column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c550d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T00:49:43.161455Z",
     "start_time": "2021-11-09T00:49:41.543089Z"
    }
   },
   "outputs": [],
   "source": [
    "y = '细菌结果'\n",
    "names = df.columns\n",
    "scaler = preprocessing.MinMaxScaler().fit(df)\n",
    "df = scaler.transform(df)\n",
    "df = pd.DataFrame(df, columns=names)\n",
    "\n",
    "df_normal_file = \"data/Diarrhea_onehot_382.tsv\"\n",
    "df.to_csv(df_normal_file, sep=\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fd6cbf",
   "metadata": {},
   "source": [
    "#### 3.1 One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41aa25",
   "metadata": {},
   "source": [
    "To repeat the RL-based experiment, you can run it from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142fad94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 383)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file = \"data/Diarrhea_onehot_382.tsv\"\n",
    "df = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fb9d0",
   "metadata": {},
   "source": [
    "#### 3.2 One-hot encoding + feature embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_file = \"data/Diarrhea_onehot_embed_482.tsv\"\n",
    "# df = pd.read_csv(df_file, sep=\"\\t\", index_col=0, encoding=\"utf-8\")\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7347d398",
   "metadata": {},
   "source": [
    "Choose any one of the above three feature encoding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d7bdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T00:49:43.241474Z",
     "start_time": "2021-11-09T00:49:43.178460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8120, 382) | X_test shape: (3480, 382)\n",
      "y_train mean: 0.2 | y_test mean: 0.2\n",
      "--------------------------------------------------\n",
      "Train set：\n",
      "0.0    0.795813\n",
      "1.0    0.204187\n",
      "Name: 细菌结果, dtype: float64\n",
      "Test set：\n",
      "0.0    0.79569\n",
      "1.0    0.20431\n",
      "Name: 细菌结果, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Stratified sampling\n",
    "# train set : test set = 7 : 3 \n",
    "y = '细菌结果'\n",
    "df_train, df_test = train_test_split(df, test_size=0.3,\n",
    "                                     stratify=df[y], random_state=42)\n",
    "\n",
    "\n",
    "# print info\n",
    "print(\"X_train shape:\", df_train.drop(y, axis=1).shape,\n",
    "      \"| X_test shape:\", df_test.drop(y, axis=1).shape,)\n",
    "print(\"y_train mean:\", round(\n",
    "    np.mean(df_train[y]), 2), \"| y_test mean:\", round(np.mean(df_test[y]), 2))\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "print(\"Train set：\")\n",
    "print(df_train[y].value_counts() / len(df_train[y]))\n",
    "print(\"Test set：\")\n",
    "print(df_test[y].value_counts() / len(df_test[y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae25902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T00:49:43.273481Z",
     "start_time": "2021-11-09T00:49:43.243475Z"
    }
   },
   "outputs": [],
   "source": [
    "y = '细菌结果'\n",
    "features_raw = df.drop(y, axis=1).columns.to_list()\n",
    "\n",
    "X_train = df_train[features_raw]\n",
    "y_train = df_train[y]\n",
    "\n",
    "X_test = df_test[features_raw]\n",
    "y_test = df_test[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d0036",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T00:49:43.289485Z",
     "start_time": "2021-11-09T00:49:43.276484Z"
    }
   },
   "outputs": [],
   "source": [
    "# f_beta\n",
    "def accuracy(input, show=False):\n",
    "    x_train = X_train.iloc[:, input]\n",
    "    x_test = X_test.iloc[:, input]\n",
    "    clf = linear_model.LogisticRegression(class_weight='balanced')\n",
    "    clf.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "\n",
    "    predicted_prob = clf.predict_proba(x_test)[:, 1]\n",
    "    predicted_test = clf.predict(x_test)\n",
    "    test_metrics = eval(x_test, y_test, predicted_test, predicted_prob, show)\n",
    "    # beta = 1.5\n",
    "    precision, recall, f_beta_test, support = precision_recall_fscore_support(\n",
    "        y_true=y_test, y_pred=predicted_test,beta=1.5)\n",
    "\n",
    "    return f_beta_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2119d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T00:49:43.321492Z",
     "start_time": "2021-11-09T00:49:43.290486Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, -1], [-1, -1], [-1, -1]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialize Q-table with -1\n",
    "# Q_values = [[-1, -1]] * len(features_raw)\n",
    "Q_values = [[-1, -1] for i in range(len(features_raw))]\n",
    "Q_values[:3]\n",
    "\n",
    "## How to add a priori weights to the features? \n",
    "# (run \"Statistical-based methods: One-hot encoding\" first and then run the following code)\n",
    "# 1. get the column names of the columns of df2, or X_chi2_anova, so that there are no y label\n",
    "# 2. find the subscripts i corresponding to these column names in df\n",
    "# 3. set the second column of row i in Q_values to 0 > 1\n",
    "\n",
    "# add a priori weights to the features\n",
    "# for ix, column in enumerate(X_train.columns):\n",
    "#     if column in X_chi2_anova.columns:\n",
    "#         Q_values[ix][1] = 0\n",
    "\n",
    "# Q_values[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d932c93e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T00:49:43.369176Z",
     "start_time": "2021-11-09T00:49:43.354500Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_reward(features):\n",
    "    if len(features) == 0:\n",
    "        return 0\n",
    "    temp = accuracy(features)\n",
    "    acc = temp * 100\n",
    "    tot_f = len(features)\n",
    "    R = acc\n",
    "    if tot_f > K:\n",
    "        R = acc * K / tot_f\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70e437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T00:49:43.383944Z",
     "start_time": "2021-11-09T00:49:43.370179Z"
    }
   },
   "outputs": [],
   "source": [
    "# epsilon-greedy policy\n",
    "epsilon = 0.5\n",
    "alpha = 0.2\n",
    "\n",
    "# attenuation coefficient\n",
    "epsilon_decay_rate = 0.995\n",
    "alpha_decay_rate = 0.995\n",
    "\n",
    "# Maximum number of features allowed\n",
    "K = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abfbc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T00:49:43.399295Z",
     "start_time": "2021-11-09T00:49:43.385229Z"
    }
   },
   "outputs": [],
   "source": [
    "all_rewards = []\n",
    "num_episodes = 100\n",
    "\n",
    "# Assign an agent to each feature\n",
    "num_agents = len(features_raw)\n",
    "\n",
    "# Initialize the reward matrix with 0\n",
    "reward_store = {}\n",
    "for i in range(num_agents + 1):\n",
    "    reward_store[i] = [0, []] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48276590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T02:58:37.062567Z",
     "start_time": "2021-11-09T00:49:43.400297Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [2:20:15<00:00, 84.16s/it] \n"
     ]
    }
   ],
   "source": [
    "# Initialize the action space with 0\n",
    "actions = [0] * num_agents\n",
    "from tqdm import tqdm\n",
    "for episode in tqdm(range(num_episodes)):\n",
    "    for agent in range(num_agents):\n",
    "        rand_number = random.uniform(0, 1)\n",
    "        if rand_number > epsilon:\n",
    "            # actions[agent]  = Q_values[agent].index(max(Q_values[agent]))\n",
    "            actions[agent] = np.argmax(Q_values[agent])\n",
    "        else:\n",
    "            actions[agent] = random.choice([0, 1])\n",
    "    features = []\n",
    "    for i, act in enumerate(actions):\n",
    "        if act == 1:\n",
    "            features.append(i)\n",
    "    # print(features)\n",
    "    R = get_reward(features)\n",
    "    if R > reward_store[len(features)][0]:\n",
    "        reward_store[len(features)] = [R, features]\n",
    "    # print(R)\n",
    "    all_rewards.append(R)\n",
    "\n",
    "    for agent in range(num_agents):\n",
    "        actions[agent] = 1 - actions[agent] \n",
    "        features = []\n",
    "        for i, act in enumerate(actions):\n",
    "            if act == 1:\n",
    "                features.append(i)\n",
    "        # CLEAN Reward：C_i = G(a-a_i+c_i) - G(a)\n",
    "        C_agent = get_reward(features) - R\n",
    "        Q_values[agent][actions[agent]] = Q_values[agent][actions[agent]] + alpha * (C_agent - Q_values[agent][actions[agent]])\n",
    "    alpha = alpha * alpha_decay_rate\n",
    "    epsilon = epsilon * epsilon_decay_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3329f22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T02:58:37.094241Z",
     "start_time": "2021-11-09T02:58:37.079238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature dimension: 202\n",
    "max(reward_store,key=reward_store.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c8986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL-based method in test set: [52.92531679698031, [2, 3, 4, 6, 9, 11, 12, 13, 14, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 35, 36, 38, 39, 41, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 65, 69, 70, 71, 72, 74, 78, 80, 82, 84, 87, 89, 91, 92, 93, 99, 102, 103, 105, 106, 107, 110, 114, 115, 116, 119, 120, 121, 122, 124, 125, 128, 131, 132, 135, 136, 137, 139, 142, 144, 146, 147, 149, 151, 152, 153, 154, 155, 158, 163, 164, 165, 169, 170, 172, 174, 175, 179, 180, 184, 186, 187, 188, 190, 192, 194, 195, 198, 201, 204, 206, 209, 210, 211, 213, 214, 216, 217, 218, 219, 221, 222, 223, 226, 228, 230, 231, 234, 235, 239, 240, 241, 242, 244, 250, 251, 252, 253, 255, 256, 259, 262, 263, 264, 266, 267, 269, 271, 272, 274, 278, 283, 284, 286, 287, 288, 290, 292, 294, 295, 298, 299, 300, 304, 307, 314, 315, 317, 319, 324, 325, 326, 327, 328, 331, 332, 333, 335, 337, 338, 341, 342, 344, 346, 347, 348, 349, 351, 352, 355, 357, 358, 363, 364, 366, 367, 370, 371, 373, 375, 377, 379, 380, 381]]\n"
     ]
    }
   ],
   "source": [
    "# The best performer in the test set\n",
    "print(\"RL-based method in test set:\", reward_store[max(reward_store,key=reward_store.get)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b23077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (overall correct predictions): 0.7164\n",
      "Auc: 0.751\n",
      "Recall (all 1s predicted right): 0.6371\n",
      "Precision (confidence when predicting a 1): 0.3832\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.74      0.81      2769\n",
      "         1.0       0.38      0.64      0.48       711\n",
      "\n",
      "    accuracy                           0.72      3480\n",
      "   macro avg       0.64      0.69      0.64      3480\n",
      "weighted avg       0.78      0.72      0.74      3480\n",
      "\n",
      "F1 value: 0.4786053882725832\n",
      "F-beta value: 0.5292531679698032\n",
      "RL-based method in test set:  0.5292531679698032\n",
      "final size of feature subset 207\n"
     ]
    }
   ],
   "source": [
    "# Extract the most effective subset according to the Q table and test it with the test set!\n",
    "\n",
    "def get_final_reward(features):\n",
    "    if len(features) == 0:\n",
    "        return 0\n",
    "    f_beta = accuracy(features, True)\n",
    "    return f_beta\n",
    "\n",
    "# use Q-table\n",
    "for agent in range(num_agents):\n",
    "        actions[agent] = np.argmax(Q_values[agent])\n",
    "   \n",
    "features = []\n",
    "for i, act in enumerate(actions):\n",
    "    if act == 1:\n",
    "        features.append(i)\n",
    "\n",
    "# use experience\n",
    "# features = reward_store[max(reward_store,key=reward_store.get)][1]\n",
    "# R = get_reward(features)\n",
    "\n",
    "R = get_final_reward(features)\n",
    "\n",
    "print(\"RL-based method in test set: \", R)\n",
    "print(\"final size of feature subset\", len(features))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb86b2e73e40408f6db468da6d9d0d4ea726460eb6a44d55f922f6aec4f641b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.448px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "636.667px",
    "left": "1279.33px",
    "right": "20px",
    "top": "144px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
